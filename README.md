# nanocortex - Unified AI System

<div align="center">

![nanocortex](https://img.shields.io/badge/nanocortex-Unified%20AI%20System-22c55e?style=for-the-badge&logo=brain&logoColor=white)

**Perceive â€¢ Reason â€¢ Act â€¢ Learn â€¢ Audit**

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![PyMuPDF](https://img.shields.io/badge/PyMuPDF-1.23+-009688?style=flat-square&logo=adobe-acrobat-reader&logoColor=white)](https://pymupdf.readthedocs.io)
[![Pydantic](https://img.shields.io/badge/Pydantic-2.0+-E92063?style=flat-square&logo=pydantic&logoColor=white)](https://docs.pydantic.dev)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-009688?style=flat-square&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![pytest](https://img.shields.io/badge/pytest-7.0+-0A9EDC?style=flat-square&logo=pytest&logoColor=white)](https://pytest.org)

</div>

---

## ğŸ¯ Overview

**nanocortex** is a production-grade, modular AI decision and control platform demonstrating how multimodal AI systems can perceive, reason, act, and learn under explicit constraintsâ€”with full auditability and human control.

- ğŸ” **Perceives** documents via PDF/image ingestion with OCR
- ğŸ“š **Retrieves** citation-grounded evidence without hallucinations
- ğŸ§  **Reasons** with policy enforcement and approval workflows
- ğŸ“ˆ **Learns** from outcomes without retraining base models
- ğŸ“‹ **Audits** every decision from input to outcome

> âš ï¸ **This is not a chatbot.** This is a *decision machine* capable of acting under constraints, explaining its outputs, and improving behavior over time.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    nanocortex Architecture                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Layer 1: Perception & Extraction            â”‚   â”‚
â”‚  â”‚        PDF Ingestion â€¢ OCR â€¢ Bounding-Box Grounding      â”‚   â”‚
â”‚  â”‚     (derived from: dex, gradia, imgshape)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Layer 2: Knowledge & Retrieval              â”‚   â”‚
â”‚  â”‚      Hybrid RAG (BM25 + Vector) â€¢ Citation Tracking      â”‚   â”‚
â”‚  â”‚     (derived from: iai-solutions-task, agentic-rag)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Layer 3: Reasoning & Control                â”‚   â”‚
â”‚  â”‚    Stateful Agents â€¢ Policy Engine â€¢ Human-in-the-Loop   â”‚   â”‚
â”‚  â”‚     (derived from: CloudRedux, antigravity)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Layer 4: Adaptation & Learning              â”‚   â”‚
â”‚  â”‚   Feedback Loop â€¢ Mistake Tracking â€¢ Auto-Adjustments    â”‚   â”‚
â”‚  â”‚     (derived from: Huemn.AI)                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Layer 5: Observability & Audit              â”‚   â”‚
â”‚  â”‚    Decision Traces â€¢ Evidence References â€¢ Override Logs â”‚   â”‚
â”‚  â”‚     (cross-cutting across all layers)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— Derived From

This repository unifies and subsumes prior evaluated projects into a cohesive reference architecture:

| Layer | Derived Repositories | Contribution |
|-------|---------------------|--------------|
| **Perception** | [dex](https://github.com/STiFLeR7/dex), [gradia](https://github.com/STiFLeR7/gradia), [imgshape](https://github.com/STiFLeR7/imgshape) | Document ingestion, extraction pipelines, image diagnostics |
| **Knowledge** | [iai-solutions-task](https://github.com/STiFLeR7/iai-solutions-task), [agentic-rag](https://github.com/STiFLeR7/agentic-rag) | Citation-grounded RAG, evidence handling |
| **Reasoning** | [CloudRedux](https://github.com/STiFLeR7/CloudRedux), [antigravity](https://github.com/STiFLeR7/antigravity) | Policy-first agent control, stateful decisions |
| **Learning** | [Huemn.AI](https://github.com/STiFLeR7/Huemn.AI) | Post-run evaluation, learning loop |

---

## ğŸ©º Real-World Testing: Clinical Decision Support

nanocortex was tested on a **Dermatology AI Decision Support** use case with 10 medical research PDFs:

```
ğŸ“ Ingested: 4 PDFs (1,365 chunks indexed)
   - A Comprehensive Review of the Acne.pdf (9 pages, 415 chunks)
   - A global perspective on the epidemiology of acne.pdf (21 pages, 337 chunks)
   - Artificial_Intelligence_in_the_Assessment_and_Grad.pdf (13 pages, 435 chunks)
   - assessment_of_life_quality_index_among_patients.pdf (6 pages, 178 chunks)
```

### Clinical Policies Applied

| Policy | Condition | Verdict |
|--------|-----------|---------|
| `treatment_approval` | contains: treatment, prescription | NEEDS_APPROVAL |
| `severity_grading` | contains: severe, moderate, grade | NEEDS_APPROVAL |
| `sensitive_populations` | contains: pediatric, pregnancy | NEEDS_APPROVAL |

### Query Results

| Query | State | Policy Triggered |
|-------|-------|-----------------|
| "What is the global prevalence of acne in adolescents?" | âœ… completed | â€” |
| "How effective is AI in grading acne severity?" | âœ… completed | â€” |
| "What treatment options are recommended for moderate acne?" | â¸ï¸ waiting_approval | `treatment_approval`, `severity_grading` |
| "How does acne affect quality of life in patients?" | âœ… completed | â€” |

### Demo Output Highlights

```
ğŸ“‹ Query: What treatment options are recommended for moderate acne?
   State: waiting_approval

   ğŸ” Policy Evaluations:
      - treatment_approval: ğŸ”´ MATCHED â†’ needs_approval
      - severity_grading: ğŸ”´ MATCHED â†’ needs_approval

   â³ Decision 4a0f7895... requires clinician approval
   ğŸ”µ Simulating clinician approval...
   âœ… Approved! Final state: completed
```

### Results

| Metric | Value |
|--------|-------|
| Accuracy | **100%** |
| Feedback recorded | 4 |
| Audit events | 26 |
| Human approvals | 1 |

ğŸ‘‰ **See [examples/](./examples/)** for the full demo

---

## ğŸ“‚ Project Structure

```
nanocortex/
â”œâ”€â”€ src/nanocortex/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ orchestrator.py      # NanoCortex entry point
â”‚   â”œâ”€â”€ perception/
â”‚   â”‚   â””â”€â”€ ingestion.py         # PDF/image extraction + OCR
â”‚   â”œâ”€â”€ knowledge/
â”‚   â”‚   â””â”€â”€ retriever.py         # Hybrid BM25 + vector RAG
â”‚   â”œâ”€â”€ reasoning/
â”‚   â”‚   â”œâ”€â”€ agent.py             # Multi-model decision agent
â”‚   â”‚   â””â”€â”€ policy.py            # Externalized rule engine
â”‚   â”œâ”€â”€ learning/
â”‚   â”‚   â””â”€â”€ feedback.py          # Outcome tracking + adjustments
â”‚   â”œâ”€â”€ audit/
â”‚   â”‚   â””â”€â”€ logger.py            # JSON-Lines event log
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ domain.py            # Pydantic domain models
â”‚   â””â”€â”€ config.py                # Environment configuration
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ audit/                   # Audit logs (JSON-Lines)
â”‚   â””â”€â”€ sample/                  # Sample documents
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ demo.py                  # Thin vertical slice demo
â”‚   â””â”€â”€ generate_sample_pdf.py   # PDF generator
â”‚
â””â”€â”€ tests/                       # pytest suite (27 tests)
```

---

## ğŸ“¡ REST API (Service Mode)

Run nanocortex as a microservice:

```powershell
uvicorn nanocortex.api.server:app --reload --port 8000
```

Open **<http://localhost:8000/docs>** for interactive Swagger docs.

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check + stats |
| `/v1/ingest` | POST | Upload and ingest document |
| `/v1/ingest/path` | POST | Ingest from local file path |
| `/v1/query` | POST | Query with retrieval + reasoning |
| `/v1/decisions/{id}/approve` | POST | Approve pending decision |
| `/v1/decisions/{id}/reject` | POST | Reject with reason |
| `/v1/feedback/{id}` | POST | Submit learning feedback |
| `/v1/learning/stats` | GET | Learning loop statistics |
| `/v1/policies` | GET/POST | List or add policy rules |
| `/v1/audit` | GET | Get audit trail |
| `/v1/audit/{id}` | GET | Get decision trace |

### Example: Query via API

```bash
# Ingest a document
curl -X POST http://localhost:8000/v1/ingest/path \
  -H "Content-Type: application/json" \
  -d '{"file_path": "./data/sample/renewable_energy_report.pdf"}'

# Query
curl -X POST http://localhost:8000/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the global solar capacity?",
    "strategy": "hybrid"
  }'

# Approve decision
curl -X POST http://localhost:8000/v1/decisions/abc123/approve
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Tesseract OCR (optional, for scanned PDFs)

### 1. Clone & Setup Environment

```powershell
# Clone the repository
git clone https://github.com/STiFLeR7/nanocortex.git
cd nanocortex

# Create Python virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# Install dependencies
pip install -e .
```

### 2. Configure Environment

Create a `.env` file in the project root:

```env
# LLM Providers (Optional - fallback mode works without these)
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# Paths
AUDIT_DIR=./data/audit
DATA_DIR=./data
```

### 3. Run the Demo

```powershell
# Generate sample PDF
python scripts/generate_sample_pdf.py

# Run thin vertical slice demo
python scripts/demo.py
```

### 4. Run Tests

```powershell
pip install -e ".[dev]"
pytest tests/ -v
```

---

## ğŸ’» Usage

```python
import asyncio
from nanocortex.api.orchestrator import NanoCortex

async def main():
    # Initialize the system
    cortex = NanoCortex()
    
    # 1. Ingest a document
    result = await cortex.ingest("data/sample/renewable_energy_report.pdf")
    print(f"Indexed {result['chunks_indexed']} chunks")
    
    # 2. Query with retrieval + reasoning
    decision = await cortex.query("What is the global solar capacity?")
    print(f"Answer: {decision['answer']}")
    print(f"State: {decision['state']}")
    
    # 3. Handle human-in-the-loop if required
    if decision['state'] == 'waiting_approval':
        cortex.approve_decision(decision['decision_id'])
    
    # 4. Submit feedback for learning
    cortex.submit_feedback(
        decision_id=decision['decision_id'],
        rating="correct",
    )
    
    # 5. View audit trail
    events = cortex.get_audit_trail(decision['decision_id'])
    print(f"Audit events: {len(events)}")

asyncio.run(main())
```

---

## ğŸ” Policy Engine

Policies are **data, not code**â€”they can be loaded from config files:

```python
from nanocortex.models.domain import PolicyRule, PolicyVerdict

# Require approval for sensitive queries
cortex.policy_engine.add_rule(PolicyRule(
    name="sensitive_topics",
    condition="contains:financial|medical|legal",
    verdict=PolicyVerdict.NEEDS_APPROVAL,
))

# Deny answers with no evidence
cortex.policy_engine.add_rule(PolicyRule(
    name="no_hallucination",
    condition="no_evidence",
    verdict=PolicyVerdict.DENY,
))
```

---

## ğŸ“Š Learning Loop

The system learns from outcomes **without retraining base models**:

| Feature | Description |
|---------|-------------|
| **Feedback Recording** | Correct, incorrect, hallucination ratings |
| **Pattern Detection** | Automatic threshold-based triggers |
| **Behavioral Adjustments** | Retrieval weights, prompt patches |
| **Persistence** | State saved across runs |

```python
stats = cortex.get_learning_stats()
print(f"Accuracy: {stats['accuracy']['accuracy']:.1%}")
print(f"Adjustments made: {stats['adjustment_count']}")
```

---

## ğŸ› ï¸ Development Status

| Component | Status |
|-----------|--------|
| Perception Layer | âœ… Complete |
| Knowledge Layer | âœ… Complete |
| Reasoning Layer | âœ… Complete |
| Learning Layer | âœ… Complete |
| Audit Layer | âœ… Complete |
| Test Suite | âœ… 27 tests passing |
| Demo Script | âœ… Complete |

---

## ğŸ”œ Recommended Stack

| Role | Model | Purpose |
|------|-------|---------|
| **Orchestrator** | GPT-5.2 Codex | Generates answers from evidence |
| **Auditor** | Claude Opus 4.6 | Reviews for hallucinations |
| **Ingestion Helper** | KimiK 2.5 | Document digestion (optional) |

> One model **acts**, one model **judges**, one model **reads**. No single-model arrogance.

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) for details.

---

<div align="center">

**Built with â¤ï¸ by STIFLER**

*A reference architecture demonstrating how AI should be allowed to act.*

</div>
